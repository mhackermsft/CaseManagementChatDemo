@page "/case/{CaseNumber}"
@using CaseManagementChatDemo.Utils
@using CaseManagementModels
@using Microsoft.Extensions.Options;
@using Microsoft.SemanticKernel
@using Microsoft.KernelMemory;
@using Microsoft.KernelMemory.AI
@using Microsoft.KernelMemory.AI.AzureOpenAI
@using Microsoft.SemanticKernel.ChatCompletion
@using MarkdownSharp
@using System.Text

@inject IHttpClientFactory HttpClientFactory
@inject IOptions<AppSettings> appSettings
@inject IJSRuntime js

<h3>Case @CaseNumber</h3>

@if (CaseDetails == null)
{
    <p><em>Loading case information and documents, please wait...</em></p>
}
else
{
    <div class="row">
        <div class="col-md-1">Name</div>
        <div class="col-md-11">@CaseDetails.CaseName</div>
    </div>
    <div class="row">
        <div class="col-md-1">Description</div>
        <div class="col-md-11">@CaseDetails.CaseDescription</div>
    </div>
    <div class="row">
        <div class="col-md-6">Plantiff: @CaseDetails.Plaintiff</div>
        <div class="col-md-6">Defendant: @CaseDetails.Defendant</div>
    </div>
    <div class="row">
        <div class="col-md-11">Documents: @CaseDetails.Documents.Count()</div>
        <br/><br/>
    </div>

    <div class="chatbox" id="MessagesInChatdiv">
        @foreach (var msg in messagesInChat)
        {
            <div>
                <b>You:</b> @(new MarkupString(msg.Prompt))
            </div>
            <div>
                <b>Assistant:</b>
                @if (isAiThinking && string.IsNullOrEmpty(msg.Completion.Trim()))
                {
                    <div class="chat-bubble">
                        <div class="typing">
                            <div class="dot"></div>
                            <div class="dot"></div>
                            <div class="dot"></div>
                        </div>
                    </div>
                }
                <span style="display:inline">
                    @(new MarkupString(Utils.StringUtils.StripOuterParagraphTags(msg.Completion)))
                </span>

                @if (msg.Citations.Count > 0)
                {
                    <br />

                    <div class="badge bg-primary">Source:</div>

                    <ul>
                        @foreach (var citation in msg.Citations)
                        {
                            <li>@(new MarkupString(citation))</li>
                        }
                    </ul>
                }
            </div>
        }          
    </div>

    <div class="row">
        <div class="col-md-5 input-group mt-3">
            <input type="text" class="form-control" placeholder="Ask a question" @bind-value="userChatMessage" @bind-value:event="oninput" @onkeydown="HandleKeyDown" />
            <button class="btn btn-primary" @onclick="sendMessage">Send</button>
            <button class="btn btn-danger" @onclick="clearMessages">Clear</button>
        </div>
    </div>
}

@code {
    #pragma warning disable SKEXP0010, SKEXP0001, SKEXP0020, KMEXP00
    [Parameter]
    public string CaseNumber { get; set; } = string.Empty;

    private CaseModel? CaseDetails { get; set; }
    private string userChatMessage = string.Empty;

    private HttpClient? _apiHttpClient;
    private HttpClient? _aiHttpClient;

    private IKernelBuilder? builder = null;
    private Kernel? kernel = null;
    private ChatHistory history = new ChatHistory();
    private MemoryServerless? kernelMemory = null;
    private IChatCompletionService? chatCompletionService = null;
    private GPT4oTokenizer? textTokenizer = null;
    private AppSettings? settings;

    private Markdown md = new Markdown();
    private List<Message> messagesInChat = new List<Message>();

    private bool isAiThinking = false;
    private bool stopResponse = false;

    protected override async Task OnInitializedAsync()
    {
        //prep http clients
        _apiHttpClient = HttpClientFactory.CreateClient("casemanagementapi");
        _aiHttpClient = HttpClientFactory.CreateClient("retryHttpClient");

        //Get app settings
        settings = new AppSettings();
        settings = appSettings.Value;

        //Setup the Tokenizer to use
        textTokenizer = new GPT4oTokenizer();

        //Prep Semantic Kernel
        builder = Kernel.CreateBuilder()
          .AddAzureOpenAIChatCompletion(settings.AzureOpenAIChatCompletion.Model, settings.AzureOpenAIChatCompletion.Endpoint, settings.AzureOpenAIChatCompletion.ApiKey, httpClient: _aiHttpClient)
          .AddAzureOpenAITextEmbeddingGeneration(settings.AzureOpenAIEmbedding.Model, settings.AzureOpenAIChatCompletion.Endpoint, settings.AzureOpenAIChatCompletion.ApiKey, httpClient: _aiHttpClient);

        // Add enterprise components
        builder.Services.AddLogging(services => services.AddConsole().SetMinimumLevel(LogLevel.Trace));

        // Build the kernel
        kernel = builder.Build();

        //Setup the memory store.
        //NOTE: This is using memory based storage which is for demo purposes only.
        //      For production use, you would want to use a persistent storage.
        //      You may run out of memory if you try to load too many documents
        //      or a large amount of content.
        var kernelMemoryBuilder = new KernelMemoryBuilder()
        .WithAzureOpenAITextEmbeddingGeneration(new AzureOpenAIConfig
            {
                APIType = AzureOpenAIConfig.APITypes.EmbeddingGeneration,
                Endpoint = settings.AzureOpenAIChatCompletion.Endpoint,
                Deployment = settings.AzureOpenAIEmbedding.Model,
                Auth = AzureOpenAIConfig.AuthTypes.APIKey,
                APIKey = settings.AzureOpenAIChatCompletion.ApiKey,
                MaxTokenTotal = settings.AzureOpenAIEmbedding.MaxInputTokens,
                MaxRetries = 3
            },
            httpClient: _aiHttpClient)
        .WithAzureOpenAITextGeneration(new AzureOpenAIConfig
            {
                APIType = AzureOpenAIConfig.APITypes.ChatCompletion,
                Endpoint = settings.AzureOpenAIChatCompletion.Endpoint,
                Deployment = settings.AzureOpenAIChatCompletion.Model,
                Auth = AzureOpenAIConfig.AuthTypes.APIKey,
                APIKey = settings.AzureOpenAIChatCompletion.ApiKey,
                MaxTokenTotal = settings.AzureOpenAIChatCompletion.MaxInputTokens,
                MaxRetries = 3
            }, httpClient: _aiHttpClient, textTokenizer: textTokenizer)
            .WithSimpleVectorDb(new Microsoft.KernelMemory.MemoryStorage.DevTools.SimpleVectorDbConfig { StorageType = Microsoft.KernelMemory.FileSystem.DevTools.FileSystemTypes.Volatile }); ;

        //Build the memory store
        kernelMemory = kernelMemoryBuilder.Build<MemoryServerless>();

        //Get reference to the chat completion service
        chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

        //Setup chat history
        history = new ChatHistory();
        history.AddSystemMessage(settings.SystemMessage);

        //Load the case details using the HttpClient named casemanagementapi
        var response = await _apiHttpClient.GetAsync($"/case/{CaseNumber}");
        response.EnsureSuccessStatusCode();
        CaseDetails = await response.Content.ReadFromJsonAsync<CaseModel>();

        //Need to see if the docs are already in the vector store. If not, we need to import them.
        //For production use you would want some way to verify that the index has all of the documents
        //and that they are up to date. Case files may change over time and this example does not
        //handle that.
        //
        //Importing documents can take significant time and resources. This is a blocking call.
        //If working with a large number of documents, you may want to look at other approaches
        //to preparing the documents and ensuring they are available in the index.
        var indexes = await kernelMemory.ListIndexesAsync();
        bool IsInIndex = indexes.Any(x => x.Name.ToLower() == CaseNumber.ToLower());
        if (!IsInIndex && CaseDetails!=null)
        {
            foreach (var document in CaseDetails.Documents)
            {
                await kernelMemory.ImportDocumentAsync(document.URI, StringUtils.RemoveInvalidCharacters(document.URI), null, CaseNumber);

                //We wait for each document to be processed before starting the next.
                //This could be changed to do things in a more async pattern to increase speed.
                while (!await kernelMemory.IsDocumentReadyAsync(StringUtils.RemoveInvalidCharacters(document.URI), CaseNumber))
                {
                    Thread.Sleep(1000);
                }
            }
        }
    }

    private async void sendMessage()
    {

        isAiThinking = false; 
        Message activeChatMessage = new Message(prompt: userChatMessage);
        messagesInChat.Add(activeChatMessage);
        userChatMessage = string.Empty;
        isAiThinking = true;
        StateHasChanged();

        //Need this delay to give the browser enough time to render the MessagesInChatdiv.
        //If this doesn't exist then it is not able to scoll to the bottom.
        await Task.Delay(100);
        await js.InvokeVoidAsync("scrollToBottom", "MessagesInChatdiv");


        //Semantic search of documents for the specific case index
        SearchResult? searchData = null;
        MemoryAnswer? answer = null;
        answer = await kernelMemory!.AskAsync(activeChatMessage.Prompt, CaseNumber);
        if (answer.NoResult)
            searchData = await kernelMemory!.SearchAsync(activeChatMessage.Prompt, CaseNumber);

        //If we got an answer from the kernelmemory, add the facts to the chat history
        if (!answer.NoResult)
        {
            history.AddUserMessage("No matter what the question or request, base the response only on the information below.");
            history.AddUserMessage(answer.Result);
            history.AddUserMessage("----------------------------------");

            if (answer.RelevantSources.Count > 0)
                foreach (var source in answer.RelevantSources)
                {
                    activeChatMessage.Citations.Add(Utils.StringUtils.CreateCitationHTML(source));
                }
        }

        //If we got a search result, add the facts to the chat history
        if (searchData != null && !searchData.NoResult)
        {
            if (searchData.Results.Count > 0)
            {
                history.AddUserMessage("No matter what the question or request, base the response only on the information below.");
                foreach (var result in searchData.Results)
                {
                    foreach (var p in result.Partitions)
                    {
                        history.AddUserMessage(p.Text);
                    }

                    //Add the source to the message
                    activeChatMessage.Citations.Add(Utils.StringUtils.CreateCitationHTML(result));

                }
                history.AddUserMessage("----------------------------------");
            }
        }

        history.AddUserMessage(activeChatMessage.Prompt);

        //Clean up history and remove old non-system messages in order to stay below our MaxInputTokens limit.
        //This is not the most efficient way to do this, but it is simple and works for this demo.
        if (settings!=null && textTokenizer!=null)
            history = AIUtils.CleanUpHistory(history, textTokenizer, settings.AzureOpenAIChatCompletion.MaxInputTokens);

        //Start AI generation
        await StreamChatCompletionAsync(history, activeChatMessage, chatCompletionService!);

    }

    public async Task StreamChatCompletionAsync(ChatHistory history,Message activeChatMessage, IChatCompletionService chatCompletionService)
    {
        isAiThinking = false;
        var assistantMessage = new StringBuilder();
        var markDownBuilder = new StringBuilder();
        await foreach (var chatUpdate in chatCompletionService.GetStreamingChatMessageContentsAsync(history))
        {
            if (stopResponse)
            {
                stopResponse = false;
                break;
            }

            markDownBuilder.Append(chatUpdate.Content);
            assistantMessage.Append(chatUpdate.Content);
            string partialHTML = md!.Transform(markDownBuilder.ToString());
            activeChatMessage.Completion = partialHTML;
            await js.InvokeVoidAsync("scrollToBottom", "MessagesInChatdiv");
            StateHasChanged();
        }

        activeChatMessage.Completion = md.Transform(assistantMessage.ToString());
        history.AddAssistantMessage(assistantMessage.ToString());
        await js.InvokeVoidAsync("scrollToBottom", "MessagesInChatdiv");
        StateHasChanged();

    }

    private void clearMessages()
    {
        stopResponse = true;
        messagesInChat.Clear();
        history.Clear();
        StateHasChanged();
    }

    private void HandleKeyDown(KeyboardEventArgs e)
    {
        if (e.Key == "Enter")
        {
            sendMessage();
        }
    }
}
